{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7dc78a",
   "metadata": {},
   "source": [
    "### CNN Model Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88426c",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe3088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88759e73",
   "metadata": {},
   "source": [
    "## Enviroment setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dedbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32fd65",
   "metadata": {},
   "source": [
    "### Get the processing device\n",
    "Check the availability of GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_list = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "device = \"gpu\" if gpu_list !=[] else \"cpu\"\n",
    "print(f\"Device available for training: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1458dc",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0812e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "dataset_path = os.path.join(os.getcwd(), \"../data/images_dataSAT\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "model_name = os.path.join(os.getcwd(), \"../models/cnn_model_keras_best.model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0053e",
   "metadata": {},
   "source": [
    "### 3. Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 64, 64\n",
    "n_channels = 3\n",
    "batch_size = 128\n",
    "lr = 0.001 #\n",
    "n_epochs = 3 \n",
    "\n",
    "steps_per_epoch = None\n",
    "validation_steps = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2d995",
   "metadata": {},
   "source": [
    "### 4. Data Augmentation and Training and Validation Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbec066",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=40, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\",\n",
    "                             validation_split=0.2\n",
    "                            )\n",
    "\n",
    "train_generator = datagen.flow_from_directory(dataset_path,\n",
    "                    target_size = (img_w, img_h),\n",
    "                    batch_size= batch_size,\n",
    "                    class_mode=\"binary\",\n",
    "                    subset=\"training\")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(dataset_path, \n",
    "                        target_size = (img_w, img_h),\n",
    "                        batch_size  = batch_size,\n",
    "                        class_mode = \"binary\",\n",
    "                        subset = \"validation\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab55b36",
   "metadata": {},
   "source": [
    "### 5. Model definition and compilation (CNN)\n",
    "\n",
    "The model architecture is composed of several key components:\n",
    "- **`Sequential`** is a linear stack of layers in Keras.\n",
    "- **Conv2D** layers perform convolution operations, acting as feature detectors.\n",
    "- **MaxPooling2D** reduces the spatial dimensions of the feature maps.\n",
    "-  **BatchNormalization** normalizes layer inputs, stabilizing and accelerating training.\n",
    "-  **GlobalAveragePooling2D** summarizes feature maps into a single vector, reducing parameters.\n",
    "-  **Dense** (fully connected) layers learn complex patterns from these features.\n",
    "-  **Dropout** is a regularization technique that randomly deactivates neurons during training.\n",
    "-  **Sigmoid** activation is used for binary classification, mapping outputs to probabilities.\n",
    "-  **HeUniform** initializer is suitable for ReLU activations.\n",
    "-  **The final output `Dense` layer** uses a `sigmoid` activation for binary classification, outputting a probability between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3259a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "                    Conv2D(32 , (5,5) , activation=\"relu\",padding=\"same\",strides=(1,1), kernel_initializer=HeUniform(), input_shape=(img_w, img_h, n_channels)),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    Conv2D(64, (5,5) , activation=\"relu\",padding=\"same\" , strides=(1,1), kernel_initializer=HeUniform()),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    Conv2D(128, (5,5) , activation=\"relu\",padding=\"same\" ,strides=(1,1), kernel_initializer=HeUniform()),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    ###\n",
    "                    Conv2D(256, (5,5) , activation=\"relu\",padding=\"same\" ,strides=(1,1), kernel_initializer=HeUniform()),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    Conv2D(512, (5,5) , activation=\"relu\",padding=\"same\" ,strides=(1,1), kernel_initializer=HeUniform()),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    Conv2D(1024, (5,5) , activation=\"relu\",padding=\"same\" ,strides=(1,1), kernel_initializer=HeUniform()),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    BatchNormalization(),\n",
    "                    \n",
    "                    \n",
    "                    ###\n",
    "                    GlobalAveragePooling2D(),\n",
    "                    \n",
    "                    Dense(64,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    Dense(128,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    Dense(256,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    ###\n",
    "                    Dense(512,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    Dense(1024,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    Dense(2048,activation=\"relu\" , kernel_initializer=HeUniform()),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.4),\n",
    "                    \n",
    "                    \n",
    "                    ###\n",
    "                    Dense(1 , activation=\"sigmoid\")\n",
    "                    \n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626def52",
   "metadata": {},
   "source": [
    "### 6. Compiling the model and displaying the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"binary_crossentropy\"\n",
    "model.compile(optimizer=Adam(learning_rate=lr),\n",
    "              loss=loss, \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8bc58",
   "metadata": {},
   "source": [
    "### 7. Checkpoint callback for model with **maximum accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(filepath=model_name,\n",
    "                                monitor='val_accuracy',\n",
    "                                mode='max',\n",
    "                                save_best_only=True,\n",
    "                                verbose=1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a966b",
   "metadata": {},
   "source": [
    "### 8. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc823fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training on : ==={device}=== with batch size: {batch_size} & lr: {lr}\")\n",
    "\n",
    "fit = model.fit(train_generator, \n",
    "                epochs= n_epochs,\n",
    "                steps_per_epoch = steps_per_epoch,\n",
    "                validation_data=(validation_generator),\n",
    "                validation_steps = validation_steps,\n",
    "                callbacks=[checkpoint_cb],\n",
    "                verbose=1\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2443d",
   "metadata": {},
   "source": [
    "### 9. Model evaluation and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(np.ceil(validation_generator.samples / validation_generator.batch_size))\n",
    "batch_size = int(validation_generator.batch_size)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for step in range(steps):\n",
    "    # Get one batch data\n",
    "    images, labels = next(validation_generator)\n",
    "    preds = model.predict(images)\n",
    "    preds = (preds > 0.5).astype(int).flatten() \n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy Score: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b02ce",
   "metadata": {},
   "source": [
    "### Visualizing the training history (accuracy and loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adf19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a subplot\n",
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot Accuracy on the first subplot\n",
    "axs.plot(fit.history['accuracy'], label='Training Accuracy')\n",
    "axs.plot(fit.history['val_accuracy'], label='Validation Accuracy')\n",
    "axs.set_title('Model Accuracy')\n",
    "axs.set_xlabel('Epochs')\n",
    "axs.set_ylabel('Accuracy')\n",
    "axs.legend()\n",
    "axs.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307a165",
   "metadata": {},
   "source": [
    "### Visualizing the training loss and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c612cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( figsize=(8, 6))\n",
    "\n",
    "\n",
    "# Plot Loss on the second subplot\n",
    "axs.plot(fit.history['loss'], label='Training Loss')\n",
    "axs.plot(fit.history['val_loss'], label='Validation Loss')\n",
    "axs.set_title('Model Loss')\n",
    "axs.set_xlabel('Epochs')\n",
    "axs.set_ylabel('Loss')\n",
    "axs.legend()\n",
    "axs.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
