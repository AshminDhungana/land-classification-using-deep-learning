{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9539d4",
   "metadata": {},
   "source": [
    "###  PyTorch Based Classifier (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43d852",
   "metadata": {},
   "source": [
    "### 1. Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d497a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported libraries\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil \n",
    "import random\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Imported libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88713af2",
   "metadata": {},
   "source": [
    "## 2. Data  preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d66236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/ashmin/Projects/land-classification-using-deep-learning/notebooks/../data/images_dataSAT\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"../data/images_dataSAT\")\n",
    "print(f\"Dataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047eeda",
   "metadata": {},
   "source": [
    "### 3. Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7aecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is cpu\n"
     ]
    }
   ],
   "source": [
    "img_size = 64\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 3 \n",
    "model_name = os.path.join(os.getcwd(), \"../models/cnn_pytorch_state_dict.pth\")\n",
    "num_classes = 2 #\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device used is {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266dcfe5",
   "metadata": {},
   "source": [
    "### 4. Data Augmentation and Training and Validation Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280cf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
    "                                      transforms.RandomRotation(40),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomAffine(0, shear=0.2),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "val_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(dataset_path, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc70080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split: Train and validation\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546684b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataLoader\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                         )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80309ad7",
   "metadata": {},
   "source": [
    "### 5 Defining the model\n",
    "\n",
    "\n",
    "- **`model = nn.Sequential(...)`**: A sequential container is used to build the model as a linear stack of layers. This is a convenient way to define a straightforward CNN.\n",
    "  - **Convolutional Blocks**: The model consists of several blocks, each containing\n",
    "      - a `Conv2d` layer for feature extraction,\n",
    "      - a `ReLU` activation function,\n",
    "      - a `MaxPool2d` layer to downsample and reduce dimensionality,\n",
    "      - a`BatchNorm2d` to stabilize and accelerate training.    \n",
    "  - **Classifier**: After the convolutional blocks,\n",
    "      - `AdaptiveAvgPool2d` reduces each feature map to a single value, making the model more robust to input size variations.\n",
    "      - `Flatten` converts the 2D feature maps into a 1D vector.\n",
    "      - `Linear` (fully connected) layers then perform the final classification,\n",
    "      - `Dropout` is used as a regularization technique to prevent overfitting.\n",
    "  - **`.to(device)`**: This moves the model's parameters and buffers to the selected device (GPU, if available otherwise CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc0650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                        # Conv Block 1\n",
    "                        nn.Conv2d(3, 32, 5, padding=2), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2), nn.BatchNorm2d(32),\n",
    "                        \n",
    "                        # Conv Block 2-6\n",
    "                        nn.Conv2d(32, 64, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2), nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 128, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2), nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 256, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2), nn.BatchNorm2d(256),\n",
    "                        nn.Conv2d(256, 512, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2), nn.BatchNorm2d(512),\n",
    "                        nn.Conv2d(512, 1024, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2), nn.BatchNorm2d(1024),\n",
    "                        \n",
    "                        # Classifier\n",
    "                        nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "                        nn.Linear(1024, 2048), nn.ReLU(), nn.BatchNorm1d(2048), nn.Dropout(0.4),\n",
    "                        nn.Linear(2048, num_classes)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890514f4",
   "metadata": {},
   "source": [
    "## 6. Training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca08d66",
   "metadata": {},
   "source": [
    "#### 6.1 Defining the training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ab353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "best_loss = float('inf')\n",
    "loss_history = {'train': [], 'val': []}\n",
    "acc_history = {'train': [], 'val': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684f87f",
   "metadata": {},
   "source": [
    "6.2 Model Traning and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on : ===cpu=== with batch size: 128 & lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 38/38 [00:57<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3098 | Val Loss: 0.0985\n",
      "Train Acc: 0.9302 | Val Acc: 0.9692\n",
      "Epoch 1 training completed in 62.23 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 38/38 [01:06<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0277 | Val Loss: 0.0094\n",
      "Train Acc: 0.9896 | Val Acc: 0.9958\n",
      "Epoch 2 training completed in 70.44 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 38/38 [01:07<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0150 | Val Loss: 0.0073\n",
      "Train Acc: 0.9952 | Val Acc: 0.9975\n",
      "Epoch 3 training completed in 71.42 seconds\n",
      "\n",
      "Trained Model. Now evaluating the model...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training on : ==={device}=== with batch size: {batch_size} & lr: {lr}\")\n",
    "\n",
    "# --- TRAINING LOOP ---\n",
    "for epoch in range(epochs):\n",
    "    # Training Phase\n",
    "    start_time = time.time() # to get the training time for each epoch\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0  # for the training metrics\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "        images, labels = images.to(device), labels.to(device)  # labels as integer class indices\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # outputs are raw logits\n",
    "        loss = criterion(outputs, labels)  # criterion is nn.CrossEntropyLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "  \n",
    "    # Synchronize CUDA before stopping timer (if using GPU)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0 #  for the validation metrics\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "  \n",
    "    # Save the best model\n",
    "    avg_val_loss = val_loss/len(val_loader)\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "    \n",
    "    # Store metrics\n",
    "    loss_history['train'].append(train_loss/len(train_loader))\n",
    "    loss_history['val'].append(val_loss/len(val_loader))\n",
    "    acc_history['train'].append(train_correct/train_total)\n",
    "    acc_history['val'].append(val_correct/val_total)\n",
    "    \n",
    "    #print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {loss_history['train'][-1]:.4f} | Val Loss: {loss_history['val'][-1]:.4f}\")\n",
    "    print(f\"Train Acc: {acc_history['train'][-1]:.4f} | Val Acc: {acc_history['val'][-1]:.4f}\")\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} training completed in {epoch_time:.2f} seconds\\n\") \n",
    "\n",
    "print(\"Trained Model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
